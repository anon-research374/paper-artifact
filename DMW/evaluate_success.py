# import json
# import numpy as np
# import math
# import time
# import os
# from transformers import AutoTokenizer, GPT2Tokenizer
# from sentence_transformers import SentenceTransformer
# from nltk.tokenize import sent_tokenize
# import torch
# import argparse
#
# # å‡è®¾è¿™äº›æ¨¡å—æ¥è‡ªæ‚¨æä¾›çš„ä»£ç 
# from sent_to_code.sent_to_code import initialize_resources, sent_to_code
#
# parser = argparse.ArgumentParser(description="ä½¿ç”¨è‡ªå®šä¹‰å‚æ•°è¿è¡Œ LLM æ•°æ®éšè—ã€‚")
# parser.add_argument('--i', type=str)
# parser.add_argument('--bit-num', type=int,default=4)
# parser.add_argument('--h', type=int,default=6)
# args = parser.parse_args()
# FILE_PATH = args.i
# BIT_LENGTH = args.bit_num
# MAT_HEIGHT = args.h
# # æ¨¡å‹å’Œæ•°æ®æ–‡ä»¶è·¯å¾„
# CC_PATH = "./sent_to_code/data/4_kmeans/cc.pt"
# EMBEDDER_PATH = "./sent_to_code/SemStamp-c4-sbert"
# STC_MATRIX_PATH = './STC_code/stc_matrix.npy'  # STC çŸ©é˜µæ–‡ä»¶è·¯å¾„
#
# # æå–å‚æ•° (è¿™äº›å‚æ•°åº”ä¸ç”Ÿæˆæ•°æ®æ—¶ä½¿ç”¨çš„å‚æ•°åŒ¹é…)
#
# DEVICE = 'cuda' if torch.cuda.is_available() else 'cpu'  # è‡ªåŠ¨æ£€æµ‹ GPU
#
#
# # --- STC æ¶ˆæ¯æå–å‡½æ•° (æ¥è‡ªæ‚¨çš„ä»£ç ) ---
#
# def get_matrix(width, height):
#     if 2 <= width <= 20 and 7 <= height <= 12:
#         # Get matrix from the pre-defined array
#         matrices = np.load(STC_MATRIX_PATH)
#         start = (height - 7) * 400 + (width - 1) * 20
#         return matrices[start:start + width]
#     else:
#         # Generate a random matrix
#         if (1 << (height - 2)) < width:
#             raise ValueError("Cannot generate matrix for this payload. Choose a higher constraint height.")
#
#         np.random.seed(1)
#         mask = (1 << (height - 2)) - 1
#         bop = (1 << (height - 1)) + 1
#         cols = []
#
#         for i in range(width):
#             while True:
#                 r = ((np.random.randint(1, mask + 1) & mask) << 1) + bop
#                 if r not in cols:
#                     cols.append(r)
#                     break
#
#         return np.array(cols, dtype=np.uint32)
#
#
# def arrange_matrices(shorter, longer, msg_length, inv_alpha):
#     """å®‰æ’å­çŸ©é˜µçš„é¡ºåºå’Œæ•°é‡"""
#     mat_type = np.zeros(msg_length, dtype=np.uint8)
#     mat_width = np.full(msg_length, shorter, dtype=np.uint32)
#     for i in range(msg_length):
#         if np.sum(mat_width[:i]) + longer <= (i + 1) * inv_alpha + 0.5:
#             mat_type[i] = 1
#             mat_width[i] = longer
#     return mat_type, mat_width
#
#
# def stc_extract(vector, alpha, msg_length, mat_height):
#     """ä»äºŒè¿›åˆ¶å‘é‡ä¸­æå– STC ç¼–ç çš„æ¶ˆæ¯"""
#     inv_alpha = 1 / alpha
#     assert inv_alpha >= 1, 'æ¶ˆæ¯é•¿åº¦ä¸èƒ½è¶…è¿‡å‘é‡é•¿åº¦!'
#     assert 4 <= mat_height <= 31, 'å­çŸ©é˜µé«˜åº¦åº”åœ¨ [4, 31] èŒƒå›´å†…!'
#
#     shorter = math.floor(inv_alpha)
#     longer = math.ceil(inv_alpha)
#     columns = [get_matrix(shorter, mat_height), get_matrix(longer, mat_height)]
#
#     binmat = [np.unpackbits(columns[0][..., np.newaxis].astype('>u4').view(np.uint8), axis=1)[:, -mat_height:][:, ::-1],
#               np.unpackbits(columns[1][..., np.newaxis].astype('>u4').view(np.uint8), axis=1)[:, -mat_height:][:, ::-1]]
#
#     mat_type, mat_width = arrange_matrices(shorter, longer, msg_length, inv_alpha)
#
#     msg = np.zeros(msg_length, dtype=np.uint8)
#     height = mat_height
#     vec_idx = 0
#
#     for msg_idx in range(msg_length):
#         for k in range(mat_width[msg_idx]):
#             if vec_idx < len(vector) and vector[vec_idx]:
#                 msg[msg_idx:msg_idx + height] ^= binmat[mat_type[msg_idx]][k][:height]
#             vec_idx += 1
#         if msg_length - msg_idx <= mat_height:
#             height -= 1
#
#     return msg
#
#
# def recover_bit(text: str, bit_num: int, device):
#     """ä»æ–‡æœ¬ä¸­æ¢å¤æ¯”ç‰¹æµ (vector)"""
#     stego_bit = []
#     # ä½¿ç”¨ nltk è¿›è¡Œå¥å­åˆ†å‰²
#     for sentence in sent_tokenize(text):
#         sentence = sentence.strip()
#         if not sentence:
#             continue
#
#         # è°ƒç”¨ sent_to_code å°†å¥å­è½¬æ¢ä¸ºæ¯”ç‰¹ä¸²
#         bitstring = sent_to_code(sentence, device, 0.01)
#
#         if bitstring is None:
#             continue
#
#         stego_bit.extend(int(b) for b in bitstring)
#
#     return stego_bit
#
#
# # --- ä¸»é€»è¾‘ ---
#
# def compare_message_accuracy(json_obj, bit_length, mat_height, device):
#     """
#     æ ¸å¿ƒå‡½æ•°ï¼šæå–å¹¶æ¯”è¾ƒæ¶ˆæ¯ï¼Œå¹¶è®¡ç®—æ¯”ç‰¹å‡†ç¡®åº¦ã€‚
#     è¿”å›ä¸€ä¸ªå…ƒç»„: (æ˜¯å¦å®Œå…¨ä¸€è‡´, æ˜¯å¦æˆåŠŸå¤„ç†, åŒ¹é…çš„æ¯”ç‰¹æ•°, æ€»æ¯”ç‰¹æ•°)ã€‚
#     """
#     try:
#         # 1. ä» JSON å¯¹è±¡ä¸­è·å–æ‰€éœ€æ•°æ®
#         idx = json_obj.get('idx', 'unknown')
#         generated_text = json_obj.get("generated_sentence")
#         original_message_str = json_obj.get("message")
#         alpha = json_obj.get("alpha")
#         msg_length = json_obj.get("msg_size")
#
#         if not all([generated_text, original_message_str, alpha is not None, msg_length is not None]):
#             print(f"å¯¹è±¡ idx {idx}: è·³è¿‡ï¼Œå› ç¼ºå°‘ 'generated_sentence', 'message', 'alpha', æˆ– 'msg_size'ã€‚")
#             # --- ä¿®æ”¹ï¼šè¿”å›ç¬¦åˆæ–°æ ¼å¼çš„å…ƒç»„ ---
#             return False, False, 0, 0
#
#         # 2. å°† JSON ä¸­çš„åŸå§‹æ¶ˆæ¯ï¼ˆå­—ç¬¦ä¸²æ ¼å¼ï¼‰è§£æä¸º numpy æ•°ç»„
#         original_message = np.array(json.loads(original_message_str))
#
#         # 3. ä»ç”Ÿæˆçš„æ–‡æœ¬ä¸­æ¢å¤éšè—çš„æ¯”ç‰¹å‘é‡ (vector)
#         time1 = time.time()
#         vector = recover_bit(generated_text, bit_length, device)
#
#         # 4. ä»æ¢å¤çš„å‘é‡ä¸­æå–æ¶ˆæ¯
#         extracted_message = stc_extract(np.array(vector), alpha, msg_length, mat_height)
#         time2 = time.time()
#         print(f'time: {time2 - time1}')
#         # --- æ–°å¢: è®¡ç®—æ¯”ç‰¹å‡†ç¡®åº¦ ---
#         original_len = len(original_message)
#         extracted_len = len(extracted_message)
#
#         # åŸºå‡†æ€»æ¯”ç‰¹æ•°æ°¸è¿œæ˜¯åŸå§‹æ¶ˆæ¯çš„é•¿åº¦
#         total_bits = original_len
#         matching_bits = 0  # é»˜è®¤ä¸º0
#
#         # åªæœ‰åœ¨æ€»æ¯”ç‰¹æ•°å¤§äº0æ—¶æ‰è¿›è¡Œæœ‰æ„ä¹‰çš„è®¡ç®—
#         if total_bits > 0:
#             # æ‰¾å‡ºéœ€è¦æ¯”è¾ƒçš„å…±åŒéƒ¨åˆ†é•¿åº¦
#             compare_len = min(original_len, extracted_len)
#             # è®¡ç®—åœ¨å…±åŒéƒ¨åˆ†çš„åŒ¹é…æ¯”ç‰¹æ•°
#             matching_bits = np.sum(original_message[:compare_len] == extracted_message[:compare_len])
#
#         # 5. æ¯”è¾ƒæ•´ä¸ªæ¶ˆæ¯æ˜¯å¦å®Œå…¨ç›¸ç­‰ (éœ€è¦é•¿åº¦å’Œå†…å®¹éƒ½ç›¸ç­‰)
#         are_equal = (original_len == extracted_len) and (matching_bits == total_bits)
#
#         if are_equal:
#             print(f"âœ… å¯¹è±¡ idx {idx}: æ¶ˆæ¯ä¸€è‡´ã€‚")
#         else:
#             print(f"âŒ å¯¹è±¡ idx {idx}: æ¶ˆæ¯ä¸ä¸€è‡´ã€‚")
#             print(f"  - åŸå§‹æ¶ˆæ¯: {original_message}")
#             print(f"  - æå–æ¶ˆæ¯: {extracted_message}")
#             # --- æ–°å¢: ä¸ºä¸ä¸€è‡´çš„æ¶ˆæ¯æ‰“å°å…¶æ¯”ç‰¹å‡†ç¡®åº¦ ---
#             if total_bits > 0:
#                 bit_acc_percent = (matching_bits / total_bits) * 100
#                 print(f"  - æ¯”ç‰¹å‡†ç¡®åº¦: {matching_bits}/{total_bits} ({bit_acc_percent:.2f}%)")
#
#         # --- ä¿®æ”¹ï¼šè¿”å›åŒ…å«æ¯”ç‰¹è®¡æ•°çš„æ–°å…ƒç»„ ---
#         return are_equal, True, matching_bits, total_bits
#
#     except Exception as e:
#         print(f"å¤„ç†å¯¹è±¡ idx {json_obj.get('idx', 'unknown')} æ—¶å‘ç”Ÿé”™è¯¯: {e}")
#         # --- ä¿®æ”¹ï¼šè¿”å›ç¬¦åˆæ–°æ ¼å¼çš„å…ƒç»„ ---
#         return False, False, 0, 0
#
#
# def main():
#     """
#     ä¸»æ‰§è¡Œå‡½æ•°
#     """
#     # åˆå§‹åŒ–è§£ç æ‰€éœ€çš„èµ„æº
#     print(f"ä½¿ç”¨è®¾å¤‡: {DEVICE}")
#     print("æ­£åœ¨åˆå§‹åŒ–èµ„æº (sent_to_code)...")
#     try:
#         initialize_resources(
#             cc_path=CC_PATH,
#             embedder_path=EMBEDDER_PATH,
#             bit_length=BIT_LENGTH
#         )
#         print("åˆå§‹åŒ–å®Œæˆã€‚")
#     except Exception as e:
#         print(f"é”™è¯¯ï¼šèµ„æºåˆå§‹åŒ–å¤±è´¥ã€‚è¯·æ£€æŸ¥è·¯å¾„ '{CC_PATH}' å’Œ '{EMBEDDER_PATH}'ã€‚")
#         print(f"è¯¦ç»†ä¿¡æ¯: {e}")
#         return
#
#     # å‡†å¤‡è®¡æ•°å™¨
#     identical_count = 0
#     different_count = 0
#     processed_count = 0
#     error_count = 0
#     total_bits_processed = 0
#     total_matching_bits = 0
#
#     print(f"\nå¼€å§‹å¤„ç†æ–‡ä»¶: '{FILE_PATH}'")
#
#     try:
#         with open(FILE_PATH, 'r', encoding='utf-8') as file:
#             for line_number, line in enumerate(file, 1):
#                 if not line.strip():
#                     continue
#
#                 try:
#                     json_obj = json.loads(line.strip())
#                     print(f"\n--- æ­£åœ¨å¤„ç†ç¬¬ {line_number} è¡Œ (idx: {json_obj.get('idx', 'unknown')}) ---")
#
#                     # å¯¹å½“å‰å¯¹è±¡è¿›è¡Œæ¶ˆæ¯å‡†ç¡®åº¦è¯„æµ‹
#                     are_equal, processed, matching, total= compare_message_accuracy(json_obj, BIT_LENGTH, MAT_HEIGHT, DEVICE)
#
#                     if processed:
#                         processed_count += 1
#                         if are_equal:
#                             identical_count += 1
#                         else:
#                             different_count += 1
#
#                         total_matching_bits += matching
#                         total_bits_processed += total
#                     else:
#                         error_count += 1
#
#                 except json.JSONDecodeError:
#                     print(f"ç¬¬ {line_number} è¡Œé”™è¯¯ï¼šJSON æ ¼å¼æ— æ•ˆã€‚")
#                     error_count += 1
#
#         # æ‰“å°æœ€ç»ˆçš„è¯„æµ‹æ‘˜è¦
#         print("\n========== è¯„æµ‹æ‘˜è¦ ==========")
#         print(f"æ€»å…±åˆ†æçš„å¯¹è±¡æ•°: {processed_count}")
#         print(f"å¤„ç†å¤±è´¥æˆ–è·³è¿‡çš„å¯¹è±¡æ•°: {error_count}")
#         print(f"âœ… æ¶ˆæ¯ä¸€è‡´çš„å¯¹è±¡æ•°: {identical_count}")
#         print(f"âŒ æ¶ˆæ¯ä¸ä¸€è‡´çš„å¯¹è±¡æ•°: {different_count}")
#
#         if processed_count > 0:
#             accuracy = (identical_count / processed_count) * 100
#             print(f"ğŸ¯ å‡†ç¡®ç‡ (Message Match Accuracy): {accuracy:.2f}%")
#             print(f'bit accuracy:{(total_matching_bits / total_bits_processed) * 100}')
#         print("===============================")
#
#     except FileNotFoundError:
#         print(f"é”™è¯¯ï¼šæ‰¾ä¸åˆ°æ–‡ä»¶ '{FILE_PATH}'ã€‚è¯·æ£€æŸ¥æ–‡ä»¶è·¯å¾„ã€‚")
#     except Exception as e:
#         print(f"å¤„ç†è¿‡ç¨‹ä¸­å‘ç”Ÿæ„å¤–é”™è¯¯: {e}")
#
#
# if __name__ == '__main__':
#     main()
#
#


import json
import numpy as np
import math
import time
import os
from transformers import AutoTokenizer, GPT2Tokenizer
from sentence_transformers import SentenceTransformer
from nltk.tokenize import sent_tokenize
import torch
import argparse
import traceback

# å‡è®¾è¿™äº›æ¨¡å—æ¥è‡ªæ‚¨æä¾›çš„ä»£ç 
from sent_to_code.sent_to_code import initialize_resources, sent_to_code

# --- å‚æ•°è§£æ ---
parser = argparse.ArgumentParser(description="ä½¿ç”¨æ•°æ®æˆªæ–­çš„è¿‘ä¼¼æ–¹æ³•ï¼Œè§£ç ç”±éæ•´æ•°å€å‚æ•°ç”Ÿæˆçš„æ•°æ®ã€‚")
parser.add_argument('--i', type=str, required=True, help="è¦å¤„ç†çš„JSONLæ•°æ®æ–‡ä»¶è·¯å¾„ã€‚")
parser.add_argument('--bit-num', type=int, default=4, help="æ¯ä¸ªå¥å­ä»£è¡¨çš„æ¯”ç‰¹æ•° (å¿…é¡»ä¸ç”Ÿæˆæ—¶ä¸€è‡´)ã€‚")
parser.add_argument('--h', type=int, default=6, help="STCçŸ©é˜µé«˜åº¦ (å¿…é¡»ä¸ç”Ÿæˆæ—¶ä¸€è‡´)ã€‚")
parser.add_argument('--seg', type=int, required=True, help="ç”Ÿæˆæ•°æ®æ—¶ä½¿ç”¨çš„æ®µé•¿åº¦ (seg)ã€‚")
args = parser.parse_args()

# --- å…¨å±€å¸¸é‡ ---
FILE_PATH = args.i
BIT_LENGTH = args.bit_num
MAT_HEIGHT = args.h
SEG_LENGTH = args.seg
CC_PATH = "./sent_to_code/data/4_kmeans/cc.pt"
EMBEDDER_PATH = "./sent_to_code/SemStamp-c4-sbert"
STC_MATRIX_PATH = './STC_code/stc_matrix.npy'
DEVICE = 'cuda' if torch.cuda.is_available() else 'cpu'


# --- æœªç»ä¿®æ”¹çš„ STC æå–ä¸è¾…åŠ©å‡½æ•° ---

def get_matrix(width, height):
    if 2 <= width <= 20 and 7 <= height <= 12 and os.path.exists(STC_MATRIX_PATH):
        matrices = np.load(STC_MATRIX_PATH)
        start = (height - 7) * 400 + (width - 1) * 20
        return matrices[start:start + width]
    else:
        if (1 << (height - 2)) < width:
            raise ValueError("Cannot generate matrix for this payload. Choose a higher constraint height.")
        np.random.seed(1)
        mask = (1 << (height - 2)) - 1
        bop = (1 << (height - 1)) + 1
        cols = []
        for i in range(width):
            while True:
                r = ((np.random.randint(1, mask + 1) & mask) << 1) + bop
                if r not in cols:
                    cols.append(r)
                    break
        return np.array(cols, dtype=np.uint32)


def arrange_matrices(shorter, longer, msg_length, inv_alpha):
    mat_type = np.zeros(msg_length, dtype=np.uint8)
    mat_width = np.full(msg_length, shorter, dtype=np.uint32)
    for i in range(msg_length):
        if np.sum(mat_width[:i]) + longer <= (i + 1) * inv_alpha + 0.5:
            mat_type[i] = 1
            mat_width[i] = longer
    return mat_type, mat_width


def stc_extract(vector, alpha, msg_length, mat_height):
    inv_alpha = 1 / alpha
    assert inv_alpha >= 1, 'æ¶ˆæ¯é•¿åº¦ä¸èƒ½è¶…è¿‡å‘é‡é•¿åº¦!'
    assert 4 <= mat_height <= 31, 'å­çŸ©é˜µé«˜åº¦åº”åœ¨ [4, 31] èŒƒå›´å†…!'
    shorter = math.floor(inv_alpha)
    longer = math.ceil(inv_alpha)
    columns = [get_matrix(shorter, mat_height), get_matrix(longer, mat_height)]
    binmat = [np.unpackbits(columns[0][..., np.newaxis].astype('>u4').view(np.uint8), axis=1)[:, -mat_height:][:, ::-1],
              np.unpackbits(columns[1][..., np.newaxis].astype('>u4').view(np.uint8), axis=1)[:, -mat_height:][:, ::-1]]
    mat_type, mat_width = arrange_matrices(shorter, longer, msg_length, inv_alpha)
    msg = np.zeros(msg_length, dtype=np.uint8)
    height = mat_height
    vec_idx = 0
    for msg_idx in range(msg_length):
        for k in range(mat_width[msg_idx]):
            if vec_idx < len(vector) and vector[vec_idx]:
                msg[msg_idx:msg_idx + height] ^= binmat[mat_type[msg_idx]][k][:height]
            vec_idx += 1
        if msg_length - msg_idx <= mat_height:
            height -= 1
    return msg


def recover_bit(text: str, bit_num: int, device: str) -> list:
    """ä»æ–‡æœ¬ä¸­æ¢å¤æ¯”ç‰¹æµ (vector)ï¼Œä¿æŒåŸæ ·"""
    stego_bit = []
    for sentence in sent_tokenize(text):
        sentence = sentence.strip()
        if not sentence: continue
        bitstring = sent_to_code(sentence, device, 0.01)
        if bitstring:
            stego_bit.extend(int(b) for b in bitstring)
    return stego_bit


# --- ä¿®æ”¹åçš„æ ¸å¿ƒå‡½æ•° ---
def compare_message_accuracy(json_obj, bit_length, mat_height, seg_length, device):
    """
    æ ¸å¿ƒå‡½æ•°ï¼šä½¿ç”¨æ•°æ®æˆªæ–­çš„è¿‘ä¼¼æ–¹æ³•ï¼Œæå–å¹¶æ¯”è¾ƒæ¶ˆæ¯ã€‚
    æœ¬æ–¹æ³•ä¼šä¸¢å¼ƒä¸å®Œæ•´æ®µè½çš„ä¿¡æ¯ï¼ŒåªéªŒè¯å®Œæ•´æ®µè½çš„éƒ¨åˆ†ã€‚
    """
    try:
        # 1. ä» JSON å¯¹è±¡ä¸­è·å–æ‰€éœ€æ•°æ®
        idx = json_obj.get('idx', 'N/A')
        generated_text = json_obj.get("generated_sentence")
        original_message_raw = json_obj.get("message")
        alpha = json_obj.get("alpha")
        msg_length = json_obj.get("msg_size")

        if not all([generated_text, original_message_raw, alpha is not None, msg_length is not None]):
            print(f"å¯¹è±¡ idx {idx}: è·³è¿‡ï¼Œç¼ºå°‘å¿…è¦å­—æ®µã€‚")
            return False, False, 0, 0

        # ==================== FIX STARTS HERE ====================
        # ä¿®æ­£: ç¨³å¥åœ°å°† "message" å­—æ®µåŠ è½½ä¸º numpy æ•°ç»„
        # æ£€æŸ¥å®ƒæ˜¯å¦ä¸ºå­—ç¬¦ä¸²ï¼Œå¦‚æœæ˜¯ï¼Œåˆ™ç”¨ json.loads() è§£æ
        if isinstance(original_message_raw, str):
            original_message_list = json.loads(original_message_raw)
        else:
            # å¦‚æœå®ƒå·²ç»æ˜¯åˆ—è¡¨ï¼ˆæˆ–å…¶å®ƒå¯è¿­ä»£å¯¹è±¡ï¼‰ï¼Œç›´æ¥ä½¿ç”¨
            original_message_list = original_message_raw

        original_message = np.array(original_message_list)
        # ===================== FIX ENDS HERE =====================

        # 2. è®¡ç®—æˆªæ–­ç‚¹
        num_full_segments = msg_length // seg_length
        truncated_msg_length = num_full_segments * seg_length

        if num_full_segments == 0:
            print(f"  [ä¿¡æ¯] å¯¹è±¡ idx {idx}: æ¶ˆæ¯æ€»é•¿ ({msg_length}) å°äºä¸€ä¸ªæ®µé•¿ ({seg_length})ï¼Œæœ¬æ–¹æ³•ä¸é€‚ç”¨ï¼Œè·³è¿‡ã€‚")
            return False, False, 0, msg_length

        print(f"  [åˆ†æ] åŸå§‹æ¶ˆæ¯ {msg_length} æ¯”ç‰¹ï¼Œæ®µé•¿ {seg_length}ã€‚åŒ…å« {num_full_segments} ä¸ªå®Œæ•´æ®µè½ã€‚")
        print(f"  [è®¡åˆ’] å°†åªéªŒè¯å‰ {truncated_msg_length} æ¯”ç‰¹çš„ä¿¡æ¯ã€‚")

        seg_num = int(seg_length / alpha / bit_length)
        num_sentences_to_keep = num_full_segments * seg_num

        # 3. å¯¹æ•°æ®è¿›è¡Œæˆªæ–­
        original_message_truncated = original_message[:truncated_msg_length]

        all_sentences = sent_tokenize(generated_text)
        if len(all_sentences) < num_sentences_to_keep:
            print(
                f"  [è­¦å‘Š] å¥å­æ•°é‡ä¸è¶³ï¼éœ€è¦çº¦ {num_sentences_to_keep} å¥ï¼Œå®é™…åªæœ‰ {len(all_sentences)} å¥ã€‚å°†ä½¿ç”¨æ‰€æœ‰å¥å­ã€‚")
            num_sentences_to_keep = len(all_sentences)

        truncated_sentences = all_sentences[:num_sentences_to_keep]
        truncated_text = " ".join(truncated_sentences)

        # 4. ä½¿ç”¨åŸå§‹çš„ã€è¿ç»­çš„è§£ç é€»è¾‘å¤„ç†æˆªæ–­åçš„æ•°æ®
        time1 = time.time()
        vector = recover_bit(truncated_text, bit_length, device)

        extracted_message = stc_extract(np.array(vector), alpha, msg_length=truncated_msg_length, mat_height=mat_height)
        time2 = time.time()
        print(f'  [æ€§èƒ½] æå–è€—æ—¶: {time2 - time1:.4f} ç§’')

        # 5. æ¯”è¾ƒæˆªæ–­åçš„ç»“æœ
        total_bits_to_check = len(original_message_truncated)
        matching_bits = np.sum(
            original_message_truncated[:len(extracted_message)] == extracted_message[:len(original_message_truncated)])
        are_equal = (len(original_message_truncated) == len(extracted_message)) and (
                    matching_bits == total_bits_to_check)

        if are_equal:
            print(f"âœ… å¯¹è±¡ idx {idx}: æ¶ˆæ¯çš„å®Œæ•´éƒ¨åˆ†ä¸€è‡´ (Partial Match)ã€‚")
            print(f"   å·²éªŒè¯ {matching_bits}/{msg_length} æ¯”ç‰¹ã€‚")
        else:
            print(f"âŒ å¯¹è±¡ idx {idx}: æ¶ˆæ¯çš„å®Œæ•´éƒ¨åˆ†ä¸ä¸€è‡´ã€‚")
            print(f"  - åŸå§‹æ¶ˆæ¯ (æˆªæ–­å {len(original_message_truncated)} bits): {original_message_truncated}")
            print(f"  - æå–æ¶ˆæ¯ ({len(extracted_message)} bits): {extracted_message}")
            if total_bits_to_check > 0:
                bit_acc_percent = (matching_bits / total_bits_to_check) * 100
                print(f"  - éƒ¨åˆ†æ¯”ç‰¹å‡†ç¡®åº¦: {matching_bits}/{total_bits_to_check} ({bit_acc_percent:.2f}%)")

        return are_equal, True, matching_bits, total_bits_to_check

    except Exception as e:
        print(f"å¤„ç†å¯¹è±¡ idx {json_obj.get('idx', 'N/A')} æ—¶å‘ç”Ÿä¸¥é‡é”™è¯¯: {e}")
        traceback.print_exc()
        return False, False, 0, 0


# --- ä¸»é€»è¾‘ (ä¸ä¹‹å‰ç›¸åŒ) ---
def main():
    print(f"ä½¿ç”¨è®¾å¤‡: {DEVICE}")
    print("æ­£åœ¨åˆå§‹åŒ–èµ„æº (sent_to_code)...")
    try:
        initialize_resources(
            cc_path=CC_PATH,
            embedder_path=EMBEDDER_PATH,
            bit_length=BIT_LENGTH
        )
        print("åˆå§‹åŒ–å®Œæˆã€‚")
    except Exception as e:
        print(f"é”™è¯¯ï¼šèµ„æºåˆå§‹åŒ–å¤±è´¥ã€‚è¯·æ£€æŸ¥è·¯å¾„ '{CC_PATH}' å’Œ '{EMBEDDER_PATH}'ã€‚è¯¦ç»†ä¿¡æ¯: {e}")
        return

    identical_count, different_count, processed_count, error_count = 0, 0, 0, 0
    total_bits_processed, total_matching_bits = 0, 0

    print(f"\nå¼€å§‹å¤„ç†æ–‡ä»¶: '{FILE_PATH}'")
    print(f"ä½¿ç”¨å‚æ•°: bit-num={BIT_LENGTH}, mat-height={MAT_HEIGHT}, seg={SEG_LENGTH}")
    print("æ³¨æ„ï¼šæœ¬è„šæœ¬ä½¿ç”¨æ•°æ®æˆªæ–­æ³•ï¼Œåªä¼šéªŒè¯æ¶ˆæ¯çš„å®Œæ•´æ®µè½éƒ¨åˆ†ã€‚")

    try:
        with open(FILE_PATH, 'r', encoding='utf-8') as file:
            for line_number, line in enumerate(file, 1):
                if not line.strip(): continue
                try:
                    json_obj = json.loads(line.strip())
                    print(f"\n--- æ­£åœ¨å¤„ç†ç¬¬ {line_number} è¡Œ (idx: {json_obj.get('idx', 'N/A')}) ---")

                    are_equal, processed, matching, total = compare_message_accuracy(
                        json_obj, BIT_LENGTH, MAT_HEIGHT, SEG_LENGTH, DEVICE
                    )

                    if processed:
                        processed_count += 1
                        if are_equal:
                            identical_count += 1
                        else:
                            different_count += 1
                        total_matching_bits += matching
                        total_bits_processed += total
                    else:
                        error_count += 1

                except json.JSONDecodeError:
                    print(f"ç¬¬ {line_number} è¡Œé”™è¯¯ï¼šJSON æ ¼å¼æ— æ•ˆã€‚")
                    error_count += 1

        print("\n========== è¯„æµ‹æ‘˜è¦ (åŸºäºæˆªæ–­æ•°æ®) ==========")
        print(f"æ€»å…±åˆ†æçš„å¯¹è±¡æ•°: {processed_count}")
        print(f"å¤„ç†å¤±è´¥æˆ–è·³è¿‡çš„å¯¹è±¡æ•°: {error_count}")
        print(f"âœ… æ¶ˆæ¯éƒ¨åˆ†ä¸€è‡´çš„å¯¹è±¡æ•°: {identical_count}")
        print(f"âŒ æ¶ˆæ¯éƒ¨åˆ†ä¸ä¸€è‡´çš„å¯¹è±¡æ•°: {different_count}")

        if processed_count > 0:
            accuracy = (identical_count / processed_count) * 100
            print(f"ğŸ¯ éƒ¨åˆ†åŒ¹é…å‡†ç¡®ç‡ (Partial Match Accuracy): {accuracy:.2f}%")
        if total_bits_processed > 0:
            bit_accuracy = (total_matching_bits / total_bits_processed) * 100
            print(
                f"éƒ¨åˆ†æ¯”ç‰¹å‡†ç¡®åº¦ (Partial Bit Accuracy): {bit_accuracy:.2f}% ({total_matching_bits}/{total_bits_processed})")
        print("==============================================")

    except FileNotFoundError:
        print(f"é”™è¯¯ï¼šæ‰¾ä¸åˆ°æ–‡ä»¶ '{FILE_PATH}'ã€‚è¯·æ£€æŸ¥æ–‡ä»¶è·¯å¾„ã€‚")
    except Exception as e:
        print(f"å¤„ç†è¿‡ç¨‹ä¸­å‘ç”Ÿæ„å¤–é”™è¯¯: {e}")


if __name__ == '__main__':
    main()